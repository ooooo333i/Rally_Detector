{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "24fdddb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary as tsummary\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa829836",
   "metadata": {},
   "source": [
    "# Prep DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b9415a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, csv_path, seq_root, seq_len=30, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.seq_root = seq_root\n",
    "        self.seq_len = seq_len\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        seq_name = row[\"sequence\"] \n",
    "        label = row[\"label\"]\n",
    "\n",
    "        seq_folder = os.path.join(self.seq_root, seq_name)\n",
    "\n",
    "        frames = []\n",
    "        for i in range(1, self.seq_len + 1):\n",
    "            img_path = os.path.join(seq_folder, f\"{i:05d}.jpg\")\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "\n",
    "            frames.append(img)\n",
    "\n",
    "        frames = torch.stack(frames)\n",
    "\n",
    "        return frames, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a3c0937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 618\n",
      "Number of validation samples: 256\n",
      "Number of test samples: 116\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ## imgnet stats\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = SeqDataset(\n",
    "    csv_path = \"Data/train/train.csv\",\n",
    "    seq_root = \"Data/train/sequences\",\n",
    "    seq_len=30,\n",
    "    transform=transform\n",
    ")\n",
    "val_dataset = SeqDataset(\n",
    "    csv_path = \"Data/validation/validation.csv\",\n",
    "    seq_root = \"Data/validation/sequences\",\n",
    "    seq_len=30,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = SeqDataset(\n",
    "    csv_path = \"Data/test/test.csv\",\n",
    "    seq_root = \"Data/test/sequences\",\n",
    "    seq_len=30,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False) \n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af3406d",
   "metadata": {},
   "source": [
    "# DEFINE MODEL\n",
    "\n",
    "### ResNet + LSTM + FC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57af47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RES_LSTM(nn.Module):\n",
    "    def __init__(self, hidden_size=128, num_layers=2, dropout= 0.0):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        RES = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        for p in RES.parameters():\n",
    "            p.requires_grad = True\n",
    "\n",
    "        modules = list(RES.children())[:-1]\n",
    "        self.cnn = nn.Sequential(*modules)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B*T, C, H, W)\n",
    "\n",
    "        feat = self.cnn(x)\n",
    "        feat = feat.view(B, T, 512)\n",
    "\n",
    "        out, _ = self.lstm(feat)\n",
    "        last = out[:, -1, :]\n",
    "\n",
    "        logit = self.fc(last)\n",
    "        return logit\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974ce4e6",
   "metadata": {},
   "source": [
    "# Define func Train / Evaludate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8e5ccc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for (x, y) in tqdm(loader, desc=\"Training\", leave=True):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).float() # label is int so convert to float\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x).squeeze(1)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = y.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        preds = (torch.sigmoid(logits) >= 0.5).long()\n",
    "        correct += (preds == y.long()).sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for (x, y) in tqdm(loader, desc=\"Evaluating\", leave=True):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device).float()\n",
    "\n",
    "        logits = model(x).squeeze(1)\n",
    "\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        batch_size = y.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "\n",
    "        preds = (torch.sigmoid(logits) >= 0.5).long()\n",
    "        correct += (preds == y.long()).sum().item()\n",
    "        total += batch_size\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22c03067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "RES_LSTM                                      [1, 1]                    --\n",
       "├─Sequential: 1-1                             [30, 512, 1, 1]           --\n",
       "│    └─Conv2d: 2-1                            [30, 64, 112, 112]        9,408\n",
       "│    └─BatchNorm2d: 2-2                       [30, 64, 112, 112]        128\n",
       "│    └─ReLU: 2-3                              [30, 64, 112, 112]        --\n",
       "│    └─MaxPool2d: 2-4                         [30, 64, 56, 56]          --\n",
       "│    └─Sequential: 2-5                        [30, 64, 56, 56]          --\n",
       "│    │    └─BasicBlock: 3-1                   [30, 64, 56, 56]          73,984\n",
       "│    │    └─BasicBlock: 3-2                   [30, 64, 56, 56]          73,984\n",
       "│    └─Sequential: 2-6                        [30, 128, 28, 28]         --\n",
       "│    │    └─BasicBlock: 3-3                   [30, 128, 28, 28]         230,144\n",
       "│    │    └─BasicBlock: 3-4                   [30, 128, 28, 28]         295,424\n",
       "│    └─Sequential: 2-7                        [30, 256, 14, 14]         --\n",
       "│    │    └─BasicBlock: 3-5                   [30, 256, 14, 14]         919,040\n",
       "│    │    └─BasicBlock: 3-6                   [30, 256, 14, 14]         1,180,672\n",
       "│    └─Sequential: 2-8                        [30, 512, 7, 7]           --\n",
       "│    │    └─BasicBlock: 3-7                   [30, 512, 7, 7]           3,673,088\n",
       "│    │    └─BasicBlock: 3-8                   [30, 512, 7, 7]           4,720,640\n",
       "│    └─AdaptiveAvgPool2d: 2-9                 [30, 512, 1, 1]           --\n",
       "├─LSTM: 1-2                                   [1, 30, 256]              1,314,816\n",
       "├─Sequential: 1-3                             [1, 1]                    --\n",
       "│    └─Linear: 2-10                           [1, 32]                   8,224\n",
       "│    └─ReLU: 2-11                             [1, 32]                   --\n",
       "│    └─Dropout: 2-12                          [1, 32]                   --\n",
       "│    └─Linear: 2-13                           [1, 1]                    33\n",
       "===============================================================================================\n",
       "Total params: 12,499,585\n",
       "Trainable params: 12,499,585\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 54.45\n",
       "===============================================================================================\n",
       "Input size (MB): 18.06\n",
       "Forward/backward pass size (MB): 1192.24\n",
       "Params size (MB): 50.00\n",
       "Estimated Total Size (MB): 1260.31\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RES_LSTM(hidden_size=256, num_layers=2, dropout=0.3)\n",
    "model = model.to(device)\n",
    "\n",
    "tsummary(model, input_size=(1, 30, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20aee49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [28:02<00:00, 21.58s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [03:15<00:00,  6.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00 | Train Loss: 0.525, Acc: 75.57% | Val Loss: 0.468, Acc: 77.73%\n",
      "improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [25:09<00:00, 19.35s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [02:24<00:00,  4.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | Train Loss: 0.404, Acc: 81.23% | Val Loss: 0.446, Acc: 78.91%\n",
      "improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [27:21<00:00, 21.04s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [02:43<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 | Train Loss: 0.372, Acc: 83.33% | Val Loss: 0.406, Acc: 80.86%\n",
      "improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [24:46<00:00, 19.06s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [03:29<00:00,  6.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 | Train Loss: 0.298, Acc: 86.89% | Val Loss: 0.570, Acc: 79.30%\n",
      "not improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [1:36:10<00:00, 73.98s/it]   \n",
      "Evaluating: 100%|██████████| 32/32 [02:19<00:00,  4.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 | Train Loss: 0.259, Acc: 89.00% | Val Loss: 0.507, Acc: 82.81%\n",
      "not improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [23:00<00:00, 17.70s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [02:23<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 | Train Loss: 0.239, Acc: 91.10% | Val Loss: 0.373, Acc: 83.59%\n",
      "improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 78/78 [20:47<00:00, 15.99s/it]\n",
      "Evaluating: 100%|██████████| 32/32 [02:26<00:00,  4.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 | Train Loss: 0.216, Acc: 92.88% | Val Loss: 0.368, Acc: 86.33%\n",
      "improved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   3%|▎         | 2/78 [00:55<35:11, 27.79s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m val_accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 16\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_one_epoch(model, train_loader, criterion, optimizer, device)\n\u001b[1;32m     17\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m% | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m )\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, y)\n\u001b[0;32m---> 13\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     16\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    627\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m _engine_run_backward(\n\u001b[1;32m    355\u001b[0m     tensors,\n\u001b[1;32m    356\u001b[0m     grad_tensors_,\n\u001b[1;32m    357\u001b[0m     retain_graph,\n\u001b[1;32m    358\u001b[0m     create_graph,\n\u001b[1;32m    359\u001b[0m     inputs_tuple,\n\u001b[1;32m    360\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    361\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    362\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    842\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    843\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "EPOCHS = 20\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
    "    \n",
    "    print(\n",
    "        f\"Epoch {epoch:02d} | \"\n",
    "        f\"Train Loss: {train_loss:.3f}, Acc: {train_acc*100:.2f}% | \"\n",
    "        f\"Val Loss: {val_loss:.3f}, Acc: {val_acc*100:.2f}%\" )\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    if val_loss < best_val_loss: # Early Stopping\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(\"improved\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(\"not improved\")\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfdae1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m9\u001b[39m, \u001b[38;5;241m4.5\u001b[39m))\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_ax, train_accuracies, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epochs_ax, val_accuracies, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m\"\u001b[39m); plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m); plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/pyplot.py:3578\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3570\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3572\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3577\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[1;32m   3579\u001b[0m         \u001b[38;5;241m*\u001b[39margs,\n\u001b[1;32m   3580\u001b[0m         scalex\u001b[38;5;241m=\u001b[39mscalex,\n\u001b[1;32m   3581\u001b[0m         scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[1;32m   3582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m   3583\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3584\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1721\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1480\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1718\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1719\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1720\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1721\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1723\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:303\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    302\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_plot_args(\n\u001b[1;32m    304\u001b[0m     axes, this, kwargs, ambiguous_fmt_datakey\u001b[38;5;241m=\u001b[39mambiguous_fmt_datakey)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/matplotlib/axes/_base.py:499\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    496\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    500\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs_ax = range(1, EPOCHS + 1)\n",
    "\n",
    "plt.figure(figsize=(9, 4.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_ax, train_accuracies, label='train')\n",
    "plt.plot(epochs_ax, val_accuracies, label='val')\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Accuracy\"); plt.title(\"Accuracy\")\n",
    "plt.xticks(list(epochs_ax))\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_ax, train_losses, label='train')\n",
    "plt.plot(epochs_ax, val_losses, label='val')\n",
    "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"Loss\")\n",
    "plt.xticks(list(epochs_ax))\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
